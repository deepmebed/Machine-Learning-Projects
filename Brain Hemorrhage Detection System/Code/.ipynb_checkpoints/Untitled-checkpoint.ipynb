{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "130dae6d-58ee-418d-b6ba-506cf960fead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images loaded: 200\n",
      "Extract features method: Method.SIMPLE\n",
      "Number of training images: 160\n",
      "Number of testing images: 40\n",
      "Training SVM model...\n",
      "SVM accuracy: 87.50%\n",
      "Number of testing images with hemorrhage: 21\n",
      "Number of testing images without hemorrhage: 19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Enum class to represent the method to extract features from the input images\n",
    "class Method(Enum):\n",
    "    SIMPLE = 1\n",
    "\n",
    "# Method to convert image to vector by resizing\n",
    "def image_to_vector(image, size):\n",
    "    return cv2.resize(image, dsize=size, interpolation=cv2.INTER_CUBIC).flatten()\n",
    "\n",
    "# Main method to extract features\n",
    "def extract_features(images,  size=(32, 32)):\n",
    "    return np.array([image_to_vector(image, size) for image in images])\n",
    "  \n",
    "       \n",
    "# Shuffle and split data into train & test sets\n",
    "def splitTestTrain(X, Y):\n",
    "    trainSize = int(0.8 * X.shape[0])\n",
    "    Y = np.reshape(Y, (Y.shape[0], 1))\n",
    "    indexes = np.arange(X.shape[0])\n",
    "    indexes = np.reshape(indexes, (X.shape[0], 1))\n",
    "    data = np.concatenate((X, Y, indexes), axis=1)\n",
    "    np.random.seed(RANDOM_SEED)  # Ensure reproducibility\n",
    "    np.random.shuffle(data)\n",
    "    trainX = data[:trainSize, :-2]\n",
    "    trainY = data[:trainSize, -2]\n",
    "    testX = data[trainSize:, :-2]\n",
    "    testY = data[trainSize:, -2]\n",
    "    imagesTest = data[trainSize:, -1]\n",
    "    return trainX, trainY, testX, testY, imagesTest\n",
    "\n",
    "# Main experiment\n",
    "if __name__ == '__main__':\n",
    "    # Load images and labels\n",
    "    pathX = \"../Dataset/head_ct/*.png\"\n",
    "    pathY = '../Dataset/labels.csv'\n",
    "    files = sorted(glob.glob(pathX))\n",
    "    labels_df = pd.read_csv(pathY)\n",
    "    labels = np.array(labels_df[' hemorrhage'].tolist())\n",
    "\n",
    "    # Define a consistent size for all images\n",
    "    target_size = (256, 256)  # Adjust as needed\n",
    "\n",
    "    # Load and resize images\n",
    "    images = []\n",
    "    for path in files:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img_resized = cv2.resize(img, target_size)\n",
    "            images.append(img_resized)\n",
    "    images = np.array(images)\n",
    "    print(f'Number of images loaded: {len(images)}')\n",
    "\n",
    "    # Choose a method to extract features\n",
    "    \n",
    "    X = extract_features(images, size=target_size)\n",
    "\n",
    "    # Split data into train & test sets, including shuffle of the data\n",
    "    trainX, trainY, testX, testY, testIm = splitTestTrain(X, labels)\n",
    "\n",
    "    # Print the number of training and testing images\n",
    "    print(f'Number of training images: {trainX.shape[0]}')\n",
    "    print(f'Number of testing images: {testX.shape[0]}')\n",
    "\n",
    "    # Train the SVM model\n",
    "    print('Training SVM model...')\n",
    "    model = SVC(kernel='linear', random_state=RANDOM_SEED)  # You can change the kernel type and other hyperparameters as needed\n",
    "    model.fit(trainX, trainY.ravel())\n",
    "\n",
    "    # Predict and evaluate the model\n",
    "    predictions = model.predict(testX)\n",
    "    accuracy = accuracy_score(testY, predictions)\n",
    "    print('SVM accuracy: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "    # Count how many test images have hemorrhage and how many do not\n",
    "    hemorrhage_count = np.sum(predictions == 1)\n",
    "    no_hemorrhage_count = np.sum(predictions == 0)\n",
    "\n",
    "    print(f'Number of testing images with hemorrhage: {hemorrhage_count}')\n",
    "    print(f'Number of testing images without hemorrhage: {no_hemorrhage_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d553bf84-4a87-45e8-9762-c62c8795aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_single_image(image_path, model, method, size):\n",
    "    # Load and preprocess the image\n",
    "   \n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read the image from path: {image_path}\")\n",
    "    image_resized = cv2.resize(image, size)\n",
    "    \n",
    "    # Extract features\n",
    "    image_features = extract_features([image_resized], method, size)\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    prediction = model.predict(image_features)\n",
    "    \n",
    "    # Map prediction to class label\n",
    "    label = \"Hemorrhage\" if prediction == 1 else \"No Hemorrhage\"\n",
    "    return label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c2e794bc-b736-4e2e-b1f9-d41a146d5a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hemorrhage\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "image_path2 = r\"/home/ahmed/dataset/099.png\"\n",
    "\n",
    "predicted_label = classify_single_image(image_path2, model, method_to_extract_features, target_size)\n",
    "\n",
    "print(predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e30d71-23ce-4bfe-9ff2-3111cb561d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a83942-9894-4472-9c0d-2690b040a23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3506e7-a34e-451b-a349-79d6345b9312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76231174-81c6-4525-b858-5ecd87548008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
